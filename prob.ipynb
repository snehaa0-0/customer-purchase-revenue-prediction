{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lifetimes as lf\n",
    "from lifetimes.plotting import plot_probability_alive_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'data\\transaction_data.csv')\n",
    "\n",
    "# Display info about the DataFrame\n",
    "df.info()\n",
    "\n",
    "# Filter out rows where UserId is -1\n",
    "df = df[df['UserId'] != -1]\n",
    "\n",
    "\n",
    "df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])\n",
    "df['SalesValue'] = df['NumberOfItemsPurchased'] * df['CostPerItem']\n",
    "\n",
    "\n",
    "\n",
    "# Ensure 'TransactionTime' is a datetime column\n",
    "df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])\n",
    "\n",
    "# Resampling by month and summing 'SalesValue'\n",
    "df_resampled = df.resample('M', on='TransactionTime')['SalesValue'].sum().reset_index()\n",
    "\n",
    "df_resampled.head()\n",
    "\n",
    "\n",
    "\n",
    "# Filtering the data between specific dates\n",
    "df_filtered = df_resampled[(df_resampled['TransactionTime'] >= '2018-01-01') & (df_resampled['TransactionTime'] <= '2019-04-01')]\n",
    "last_date = df_filtered['TransactionTime'].max()\n",
    "df_filtered.head()\n",
    "last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the sales values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_filtered['TransactionTime'], df_filtered['SalesValue'], label='Sales Value', color='blue')\n",
    "plt.title('Sales Value from Jan 2018 to Apr 2019')\n",
    "plt.xlabel('Transaction Time')\n",
    "plt.ylabel('Sales Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a summary DataFrame from the original dataset (not the resampled one)\n",
    "summary_df = lf.utils.summary_data_from_transaction_data(\n",
    "    df,  # Use the original dataset for summary\n",
    "    customer_id_col='UserId', \n",
    "    datetime_col='TransactionTime', \n",
    "    monetary_value_col='SalesValue',\n",
    "    observation_period_end=last_date\n",
    ")\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df[summary_df['monetary_value'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import BetaGeoFitter\n",
    "bgf = BetaGeoFitter(penalizer_coef=0.15)\n",
    "#The BG/NBD model is used to predict the number of repeat purchases a customer will make in the future.\n",
    "# The penalizer coefficient (penalizer_coef=0.15) is included to regularize the model and prevent overfitting.\n",
    "# If the model doesn’t converge, increasing the penalizer coefficient might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgf.fit(summary_df['frequency'], summary_df['recency'], summary_df['T'])\n",
    "#the fit() method trains the BG/NBD model. It uses the following columns:\n",
    "#frequency: Number of repeat purchases made by the customer.\n",
    "#recency: Time between the customer’s first and most recent purchase.\n",
    "#T: The duration for which the customer has been observed (from their first purchase to the end of the observation period)\n",
    "print(bgf.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probability_alive_matrix(bgf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#his plot shows the probability that a customer is still \"alive\" (i.e., has not churned) based on their recency and frequency using the BG/NBD model.\n",
    "'''\n",
    "Explanation:\n",
    "X-axis (Customer’s Historical Frequency):\n",
    "\n",
    "This represents how many repeat purchases the customer has made historically.\n",
    "As frequency increases, it generally indicates a more engaged customer.\n",
    "Y-axis (Customer’s Recency):\n",
    "\n",
    "This represents how recently the customer made a purchase.\n",
    "Higher values mean the customer hasn't made a purchase for a long time, while lower values indicate recent purchases.\n",
    "Color Scale (Probability of Being Alive):\n",
    "\n",
    "The color gradient represents the probability that a customer is still \"alive\" and will make repeat purchases in the future.\n",
    "Yellow (1.0): High probability of the customer still being active.\n",
    "Purple (0.0): Low probability of the customer still being active (i.e., more likely to have churned).\n",
    "Insights:\n",
    "Customers with low recency (recent purchasers) and high frequency (frequent buyers) are very likely to still be \"alive\" and continue making purchases (yellow area in the bottom right).\n",
    "Customers with high recency (haven't purchased in a long time) and low frequency (few purchases) are less likely to make another purchase (purple area in the top left).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Ensure you import numpy\n",
    "\n",
    "summary_df['predicted_purchases_90'] = np.floor(bgf.conditional_expected_number_of_purchases_up_to_time(\n",
    "    t=90,  # For the next 90 days\n",
    "    frequency=summary_df['frequency'], \n",
    "    recency=summary_df['recency'], \n",
    "    T=summary_df['T']\n",
    ")).astype(int)\n",
    "summary_df['predicted_purchases_oneyear'] = np.floor(bgf.conditional_expected_number_of_purchases_up_to_time(\n",
    "    t=360,  # For the next 90 days\n",
    "    frequency=summary_df['frequency'], \n",
    "    recency=summary_df['recency'], \n",
    "    T=summary_df['T']\n",
    ")).astype(int)   # Convert to integer\n",
    "\n",
    "# Displaying the first few rows\n",
    "print(summary_df[['frequency', 'recency', 'T', 'predicted_purchases_90','predicted_purchases_oneyear']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary_df to a CSV file\n",
    "summary_df.to_csv('summary_features.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clv_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
