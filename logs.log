2024-11-15 00:58:14,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-15 00:58:14,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-15 00:58:14,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-15 00:58:14,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-15 01:08:44,888:WARNING:C:\Users\vsneh\AppData\Local\Temp\ipykernel_33148\43177082.py:1: FutureWarning: Parsed string "Sat Feb 02 12:50:00 IST 2019" included an un-recognized timezone "IST". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.
  df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])

2024-11-16 02:33:28,039:WARNING:C:\Users\vsneh\AppData\Local\Temp\ipykernel_33148\3932512145.py:10: FutureWarning: Parsed string "Sat Feb 02 12:50:00 IST 2019" included an un-recognized timezone "IST". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.
  df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])

2024-11-26 01:49:19,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-26 01:49:19,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-26 01:49:19,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-26 01:49:19,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-26 01:50:48,916:WARNING:C:\Users\vsneh\AppData\Local\Temp\ipykernel_24188\2076730307.py:12: FutureWarning: Parsed string "Sat Feb 02 12:50:00 IST 2019" included an un-recognized timezone "IST". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.
  df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])

2024-11-26 01:59:14,010:WARNING:C:\Users\vsneh\AppData\Local\Temp\ipykernel_24188\3133287862.py:12: FutureWarning: Parsed string "Sat Feb 02 12:50:00 IST 2019" included an un-recognized timezone "IST". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.
  df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])

2024-11-26 02:02:26,531:WARNING:C:\Users\vsneh\AppData\Local\Temp\ipykernel_24188\660062111.py:12: FutureWarning: Parsed string "Sat Feb 02 12:50:00 IST 2019" included an un-recognized timezone "IST". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.
  df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])

2024-11-26 02:05:26,444:WARNING:C:\Users\vsneh\AppData\Local\Temp\ipykernel_24188\524341276.py:2: FutureWarning: Parsed string "Sat Feb 02 12:50:00 IST 2019" included an un-recognized timezone "IST". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.
  df['TransactionTime'] = pd.to_datetime(df['TransactionTime'])

2024-11-26 02:17:43,816:INFO:PyCaret ClassificationExperiment
2024-11-26 02:17:43,816:INFO:Logging name: clf-default-name
2024-11-26 02:17:43,816:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-26 02:17:43,816:INFO:version 3.3.2
2024-11-26 02:17:43,816:INFO:Initializing setup()
2024-11-26 02:17:43,816:INFO:self.USI: c7a9
2024-11-26 02:17:43,816:INFO:self._variable_keys: {'gpu_param', 'X', 'fold_generator', 'X_test', 'fold_groups_param', 'exp_name_log', 'y', '_available_plots', 'idx', 'y_test', 'is_multiclass', 'memory', 'exp_id', 'log_plots_param', 'X_train', 'target_param', '_ml_usecase', 'gpu_n_jobs_param', 'logging_param', 'seed', 'y_train', 'USI', 'html_param', 'fix_imbalance', 'fold_shuffle_param', 'pipeline', 'data', 'n_jobs_param'}
2024-11-26 02:17:43,816:INFO:Checking environment
2024-11-26 02:17:43,816:INFO:python_version: 3.11.10
2024-11-26 02:17:43,816:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-11-26 02:17:43,816:INFO:machine: AMD64
2024-11-26 02:17:43,816:INFO:platform: Windows-10-10.0.22631-SP0
2024-11-26 02:17:43,817:INFO:Memory: svmem(total=16849256448, available=1981693952, percent=88.2, used=14867562496, free=1981693952)
2024-11-26 02:17:43,817:INFO:Physical Core: 10
2024-11-26 02:17:43,817:INFO:Logical Core: 16
2024-11-26 02:17:43,817:INFO:Checking libraries
2024-11-26 02:17:43,817:INFO:System:
2024-11-26 02:17:43,817:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-11-26 02:17:43,817:INFO:executable: c:\Users\vsneh\anaconda3\envs\ml_environment\python.exe
2024-11-26 02:17:43,817:INFO:   machine: Windows-10-10.0.22631-SP0
2024-11-26 02:17:43,817:INFO:PyCaret required dependencies:
2024-11-26 02:17:43,991:INFO:                 pip: 24.2
2024-11-26 02:17:43,991:INFO:          setuptools: 75.1.0
2024-11-26 02:17:43,991:INFO:             pycaret: 3.3.2
2024-11-26 02:17:43,991:INFO:             IPython: 8.27.0
2024-11-26 02:17:43,991:INFO:          ipywidgets: 8.1.5
2024-11-26 02:17:43,991:INFO:                tqdm: 4.66.5
2024-11-26 02:17:43,991:INFO:               numpy: 1.26.4
2024-11-26 02:17:43,991:INFO:              pandas: 2.1.4
2024-11-26 02:17:43,991:INFO:              jinja2: 3.1.4
2024-11-26 02:17:43,991:INFO:               scipy: 1.11.4
2024-11-26 02:17:43,991:INFO:              joblib: 1.3.2
2024-11-26 02:17:43,991:INFO:             sklearn: 1.4.2
2024-11-26 02:17:43,991:INFO:                pyod: 2.0.2
2024-11-26 02:17:43,991:INFO:            imblearn: 0.12.4
2024-11-26 02:17:43,991:INFO:   category_encoders: 2.6.4
2024-11-26 02:17:43,991:INFO:            lightgbm: 4.5.0
2024-11-26 02:17:43,991:INFO:               numba: 0.60.0
2024-11-26 02:17:43,991:INFO:            requests: 2.32.3
2024-11-26 02:17:43,991:INFO:          matplotlib: 3.7.5
2024-11-26 02:17:43,991:INFO:          scikitplot: 0.3.7
2024-11-26 02:17:43,991:INFO:         yellowbrick: 1.5
2024-11-26 02:17:43,991:INFO:              plotly: 5.24.1
2024-11-26 02:17:43,991:INFO:    plotly-resampler: Not installed
2024-11-26 02:17:43,991:INFO:             kaleido: 0.2.1
2024-11-26 02:17:43,991:INFO:           schemdraw: 0.15
2024-11-26 02:17:43,991:INFO:         statsmodels: 0.14.4
2024-11-26 02:17:43,991:INFO:              sktime: 0.26.0
2024-11-26 02:17:43,991:INFO:               tbats: 1.1.3
2024-11-26 02:17:43,991:INFO:            pmdarima: 2.0.4
2024-11-26 02:17:43,992:INFO:              psutil: 5.9.0
2024-11-26 02:17:43,992:INFO:          markupsafe: 2.1.3
2024-11-26 02:17:43,992:INFO:             pickle5: Not installed
2024-11-26 02:17:43,992:INFO:         cloudpickle: 3.0.0
2024-11-26 02:17:43,992:INFO:         deprecation: 2.1.0
2024-11-26 02:17:43,992:INFO:              xxhash: 3.5.0
2024-11-26 02:17:43,992:INFO:           wurlitzer: Not installed
2024-11-26 02:17:43,992:INFO:PyCaret optional dependencies:
2024-11-26 02:17:44,074:INFO:                shap: 0.46.0
2024-11-26 02:17:44,074:INFO:           interpret: Not installed
2024-11-26 02:17:44,074:INFO:                umap: Not installed
2024-11-26 02:17:44,074:INFO:     ydata_profiling: Not installed
2024-11-26 02:17:44,075:INFO:  explainerdashboard: Not installed
2024-11-26 02:17:44,075:INFO:             autoviz: Not installed
2024-11-26 02:17:44,075:INFO:           fairlearn: Not installed
2024-11-26 02:17:44,075:INFO:          deepchecks: Not installed
2024-11-26 02:17:44,075:INFO:             xgboost: 2.1.1
2024-11-26 02:17:44,075:INFO:            catboost: Not installed
2024-11-26 02:17:44,075:INFO:              kmodes: Not installed
2024-11-26 02:17:44,075:INFO:             mlxtend: Not installed
2024-11-26 02:17:44,075:INFO:       statsforecast: Not installed
2024-11-26 02:17:44,075:INFO:        tune_sklearn: Not installed
2024-11-26 02:17:44,075:INFO:                 ray: Not installed
2024-11-26 02:17:44,075:INFO:            hyperopt: Not installed
2024-11-26 02:17:44,075:INFO:              optuna: 4.1.0
2024-11-26 02:17:44,075:INFO:               skopt: Not installed
2024-11-26 02:17:44,075:INFO:              mlflow: 2.17.2
2024-11-26 02:17:44,075:INFO:              gradio: Not installed
2024-11-26 02:17:44,075:INFO:             fastapi: Not installed
2024-11-26 02:17:44,075:INFO:             uvicorn: Not installed
2024-11-26 02:17:44,075:INFO:              m2cgen: Not installed
2024-11-26 02:17:44,075:INFO:           evidently: Not installed
2024-11-26 02:17:44,075:INFO:               fugue: Not installed
2024-11-26 02:17:44,075:INFO:           streamlit: Not installed
2024-11-26 02:17:44,075:INFO:             prophet: Not installed
2024-11-26 02:17:44,075:INFO:None
2024-11-26 02:17:44,075:INFO:Set up data.
2024-11-26 02:17:44,079:INFO:Set up folding strategy.
2024-11-26 02:17:44,079:INFO:Set up train/test split.
2024-11-26 02:17:44,086:INFO:Set up index.
2024-11-26 02:17:44,087:INFO:Assigning column types.
2024-11-26 02:17:44,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-26 02:17:44,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:17:44,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-26 02:17:44,137:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:17:44,162:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-26 02:17:44,177:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,178:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-26 02:17:44,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-26 02:17:44,215:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-26 02:17:44,254:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,255:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-26 02:17:44,292:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,331:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,334:INFO:Preparing preprocessing pipeline...
2024-11-26 02:17:44,336:INFO:Set up simple imputation.
2024-11-26 02:17:44,350:INFO:Finished creating preprocessing pipeline.
2024-11-26 02:17:44,353:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vsneh\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['UserId', 'recency', 'frequency',
                                             'sales_value_sum',
                                             'sales_value_mean',
                                             'transactions_last_month',
                                             'transactions_last_2weeks',
                                             'sales_value_last_2weeks',
                                             'sales_90_value'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-11-26 02:17:44,353:INFO:Creating final display dataframe.
2024-11-26 02:17:44,391:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     sales_90_flag
2                   Target type            Binary
3           Original data shape        (4368, 10)
4        Transformed data shape        (4368, 10)
5   Transformed train set shape        (3057, 10)
6    Transformed test set shape        (1311, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c7a9
2024-11-26 02:17:44,435:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,475:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:17:44,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:17:44,477:INFO:setup() successfully completed in 0.66s...............
2024-11-26 02:18:00,107:INFO:Initializing compare_models()
2024-11-26 02:18:00,107:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-26 02:18:00,108:INFO:Checking exceptions
2024-11-26 02:18:00,112:INFO:Preparing display monitor
2024-11-26 02:18:00,131:INFO:Initializing Logistic Regression
2024-11-26 02:18:00,131:INFO:Total runtime is 0.0 minutes
2024-11-26 02:18:00,135:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:00,135:INFO:Initializing create_model()
2024-11-26 02:18:00,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:00,136:INFO:Checking exceptions
2024-11-26 02:18:00,136:INFO:Importing libraries
2024-11-26 02:18:00,136:INFO:Copying training dataset
2024-11-26 02:18:00,139:INFO:Defining folds
2024-11-26 02:18:00,139:INFO:Declaring metric variables
2024-11-26 02:18:00,141:INFO:Importing untrained model
2024-11-26 02:18:00,145:INFO:Logistic Regression Imported successfully
2024-11-26 02:18:00,152:INFO:Starting cross validation
2024-11-26 02:18:00,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:03,482:INFO:Calculating mean and std
2024-11-26 02:18:03,484:INFO:Creating metrics dataframe
2024-11-26 02:18:03,486:INFO:Uploading results into container
2024-11-26 02:18:03,488:INFO:Uploading model into container now
2024-11-26 02:18:03,490:INFO:_master_model_container: 1
2024-11-26 02:18:03,490:INFO:_display_container: 2
2024-11-26 02:18:03,491:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-26 02:18:03,491:INFO:create_model() successfully completed......................................
2024-11-26 02:18:03,653:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:03,653:INFO:Creating metrics dataframe
2024-11-26 02:18:03,658:INFO:Initializing K Neighbors Classifier
2024-11-26 02:18:03,658:INFO:Total runtime is 0.05879525740941365 minutes
2024-11-26 02:18:03,660:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:03,660:INFO:Initializing create_model()
2024-11-26 02:18:03,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:03,661:INFO:Checking exceptions
2024-11-26 02:18:03,661:INFO:Importing libraries
2024-11-26 02:18:03,661:INFO:Copying training dataset
2024-11-26 02:18:03,664:INFO:Defining folds
2024-11-26 02:18:03,664:INFO:Declaring metric variables
2024-11-26 02:18:03,666:INFO:Importing untrained model
2024-11-26 02:18:03,669:INFO:K Neighbors Classifier Imported successfully
2024-11-26 02:18:03,674:INFO:Starting cross validation
2024-11-26 02:18:03,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:03,765:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:03,767:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:03,769:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,336:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,337:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,337:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,337:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,339:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,342:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,358:INFO:Calculating mean and std
2024-11-26 02:18:05,359:INFO:Creating metrics dataframe
2024-11-26 02:18:05,361:INFO:Uploading results into container
2024-11-26 02:18:05,362:INFO:Uploading model into container now
2024-11-26 02:18:05,362:INFO:_master_model_container: 2
2024-11-26 02:18:05,363:INFO:_display_container: 2
2024-11-26 02:18:05,363:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-26 02:18:05,363:INFO:create_model() successfully completed......................................
2024-11-26 02:18:05,500:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:05,500:INFO:Creating metrics dataframe
2024-11-26 02:18:05,507:INFO:Initializing Naive Bayes
2024-11-26 02:18:05,507:INFO:Total runtime is 0.08961059252421061 minutes
2024-11-26 02:18:05,509:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:05,509:INFO:Initializing create_model()
2024-11-26 02:18:05,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:05,509:INFO:Checking exceptions
2024-11-26 02:18:05,509:INFO:Importing libraries
2024-11-26 02:18:05,509:INFO:Copying training dataset
2024-11-26 02:18:05,513:INFO:Defining folds
2024-11-26 02:18:05,513:INFO:Declaring metric variables
2024-11-26 02:18:05,516:INFO:Importing untrained model
2024-11-26 02:18:05,519:INFO:Naive Bayes Imported successfully
2024-11-26 02:18:05,524:INFO:Starting cross validation
2024-11-26 02:18:05,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:05,574:INFO:Calculating mean and std
2024-11-26 02:18:05,574:INFO:Creating metrics dataframe
2024-11-26 02:18:05,575:INFO:Uploading results into container
2024-11-26 02:18:05,576:INFO:Uploading model into container now
2024-11-26 02:18:05,576:INFO:_master_model_container: 3
2024-11-26 02:18:05,576:INFO:_display_container: 2
2024-11-26 02:18:05,576:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-26 02:18:05,576:INFO:create_model() successfully completed......................................
2024-11-26 02:18:05,700:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:05,700:INFO:Creating metrics dataframe
2024-11-26 02:18:05,705:INFO:Initializing Decision Tree Classifier
2024-11-26 02:18:05,705:INFO:Total runtime is 0.09290496110916137 minutes
2024-11-26 02:18:05,707:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:05,708:INFO:Initializing create_model()
2024-11-26 02:18:05,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:05,708:INFO:Checking exceptions
2024-11-26 02:18:05,708:INFO:Importing libraries
2024-11-26 02:18:05,708:INFO:Copying training dataset
2024-11-26 02:18:05,712:INFO:Defining folds
2024-11-26 02:18:05,712:INFO:Declaring metric variables
2024-11-26 02:18:05,713:INFO:Importing untrained model
2024-11-26 02:18:05,716:INFO:Decision Tree Classifier Imported successfully
2024-11-26 02:18:05,720:INFO:Starting cross validation
2024-11-26 02:18:05,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:05,768:INFO:Calculating mean and std
2024-11-26 02:18:05,769:INFO:Creating metrics dataframe
2024-11-26 02:18:05,769:INFO:Uploading results into container
2024-11-26 02:18:05,769:INFO:Uploading model into container now
2024-11-26 02:18:05,770:INFO:_master_model_container: 4
2024-11-26 02:18:05,770:INFO:_display_container: 2
2024-11-26 02:18:05,770:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-26 02:18:05,770:INFO:create_model() successfully completed......................................
2024-11-26 02:18:05,893:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:05,893:INFO:Creating metrics dataframe
2024-11-26 02:18:05,899:INFO:Initializing SVM - Linear Kernel
2024-11-26 02:18:05,899:INFO:Total runtime is 0.09613756338755289 minutes
2024-11-26 02:18:05,900:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:05,901:INFO:Initializing create_model()
2024-11-26 02:18:05,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:05,901:INFO:Checking exceptions
2024-11-26 02:18:05,901:INFO:Importing libraries
2024-11-26 02:18:05,901:INFO:Copying training dataset
2024-11-26 02:18:05,904:INFO:Defining folds
2024-11-26 02:18:05,905:INFO:Declaring metric variables
2024-11-26 02:18:05,907:INFO:Importing untrained model
2024-11-26 02:18:05,909:INFO:SVM - Linear Kernel Imported successfully
2024-11-26 02:18:05,913:INFO:Starting cross validation
2024-11-26 02:18:05,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:05,945:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,946:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,946:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,946:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,946:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:05,962:INFO:Calculating mean and std
2024-11-26 02:18:05,962:INFO:Creating metrics dataframe
2024-11-26 02:18:05,963:INFO:Uploading results into container
2024-11-26 02:18:05,963:INFO:Uploading model into container now
2024-11-26 02:18:05,963:INFO:_master_model_container: 5
2024-11-26 02:18:05,963:INFO:_display_container: 2
2024-11-26 02:18:05,964:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-26 02:18:05,964:INFO:create_model() successfully completed......................................
2024-11-26 02:18:06,086:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:06,086:INFO:Creating metrics dataframe
2024-11-26 02:18:06,091:INFO:Initializing Ridge Classifier
2024-11-26 02:18:06,091:INFO:Total runtime is 0.09934035142262776 minutes
2024-11-26 02:18:06,093:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:06,094:INFO:Initializing create_model()
2024-11-26 02:18:06,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:06,094:INFO:Checking exceptions
2024-11-26 02:18:06,094:INFO:Importing libraries
2024-11-26 02:18:06,094:INFO:Copying training dataset
2024-11-26 02:18:06,097:INFO:Defining folds
2024-11-26 02:18:06,097:INFO:Declaring metric variables
2024-11-26 02:18:06,099:INFO:Importing untrained model
2024-11-26 02:18:06,102:INFO:Ridge Classifier Imported successfully
2024-11-26 02:18:06,105:INFO:Starting cross validation
2024-11-26 02:18:06,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:06,133:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89687e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:06,133:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.8966e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:06,133:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.00471e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:06,133:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89986e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:06,133:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89653e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:06,134:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89989e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:06,140:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,142:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,142:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,143:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,144:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,144:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,152:INFO:Calculating mean and std
2024-11-26 02:18:06,152:INFO:Creating metrics dataframe
2024-11-26 02:18:06,153:INFO:Uploading results into container
2024-11-26 02:18:06,153:INFO:Uploading model into container now
2024-11-26 02:18:06,154:INFO:_master_model_container: 6
2024-11-26 02:18:06,154:INFO:_display_container: 2
2024-11-26 02:18:06,154:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-26 02:18:06,154:INFO:create_model() successfully completed......................................
2024-11-26 02:18:06,274:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:06,274:INFO:Creating metrics dataframe
2024-11-26 02:18:06,278:INFO:Initializing Random Forest Classifier
2024-11-26 02:18:06,278:INFO:Total runtime is 0.10246161619822183 minutes
2024-11-26 02:18:06,281:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:06,281:INFO:Initializing create_model()
2024-11-26 02:18:06,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:06,281:INFO:Checking exceptions
2024-11-26 02:18:06,281:INFO:Importing libraries
2024-11-26 02:18:06,281:INFO:Copying training dataset
2024-11-26 02:18:06,284:INFO:Defining folds
2024-11-26 02:18:06,284:INFO:Declaring metric variables
2024-11-26 02:18:06,286:INFO:Importing untrained model
2024-11-26 02:18:06,288:INFO:Random Forest Classifier Imported successfully
2024-11-26 02:18:06,291:INFO:Starting cross validation
2024-11-26 02:18:06,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:06,610:INFO:Calculating mean and std
2024-11-26 02:18:06,611:INFO:Creating metrics dataframe
2024-11-26 02:18:06,612:INFO:Uploading results into container
2024-11-26 02:18:06,613:INFO:Uploading model into container now
2024-11-26 02:18:06,613:INFO:_master_model_container: 7
2024-11-26 02:18:06,613:INFO:_display_container: 2
2024-11-26 02:18:06,613:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-26 02:18:06,613:INFO:create_model() successfully completed......................................
2024-11-26 02:18:06,730:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:06,730:INFO:Creating metrics dataframe
2024-11-26 02:18:06,735:INFO:Initializing Quadratic Discriminant Analysis
2024-11-26 02:18:06,735:INFO:Total runtime is 0.11007666985193887 minutes
2024-11-26 02:18:06,738:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:06,738:INFO:Initializing create_model()
2024-11-26 02:18:06,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:06,738:INFO:Checking exceptions
2024-11-26 02:18:06,738:INFO:Importing libraries
2024-11-26 02:18:06,738:INFO:Copying training dataset
2024-11-26 02:18:06,741:INFO:Defining folds
2024-11-26 02:18:06,742:INFO:Declaring metric variables
2024-11-26 02:18:06,744:INFO:Importing untrained model
2024-11-26 02:18:06,746:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-26 02:18:06,749:INFO:Starting cross validation
2024-11-26 02:18:06,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:06,785:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-26 02:18:06,785:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-26 02:18:06,785:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-26 02:18:06,785:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-26 02:18:06,785:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-26 02:18:06,785:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,788:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,789:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))


2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,790:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,791:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,791:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,791:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,791:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,791:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,791:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-26 02:18:06,792:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,795:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,797:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-26 02:18:06,798:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,798:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,798:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,798:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,798:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,800:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,800:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,801:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,801:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:06,807:INFO:Calculating mean and std
2024-11-26 02:18:06,807:INFO:Creating metrics dataframe
2024-11-26 02:18:06,807:INFO:Uploading results into container
2024-11-26 02:18:06,808:INFO:Uploading model into container now
2024-11-26 02:18:06,809:INFO:_master_model_container: 8
2024-11-26 02:18:06,809:INFO:_display_container: 2
2024-11-26 02:18:06,809:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-26 02:18:06,809:INFO:create_model() successfully completed......................................
2024-11-26 02:18:06,931:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:06,931:INFO:Creating metrics dataframe
2024-11-26 02:18:06,936:INFO:Initializing Ada Boost Classifier
2024-11-26 02:18:06,936:INFO:Total runtime is 0.1134193698565165 minutes
2024-11-26 02:18:06,937:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:06,938:INFO:Initializing create_model()
2024-11-26 02:18:06,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:06,938:INFO:Checking exceptions
2024-11-26 02:18:06,938:INFO:Importing libraries
2024-11-26 02:18:06,938:INFO:Copying training dataset
2024-11-26 02:18:06,941:INFO:Defining folds
2024-11-26 02:18:06,942:INFO:Declaring metric variables
2024-11-26 02:18:06,944:INFO:Importing untrained model
2024-11-26 02:18:06,946:INFO:Ada Boost Classifier Imported successfully
2024-11-26 02:18:06,950:INFO:Starting cross validation
2024-11-26 02:18:06,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:06,972:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,973:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,975:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,976:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,976:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,982:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,984:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:06,984:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-26 02:18:07,207:INFO:Calculating mean and std
2024-11-26 02:18:07,207:INFO:Creating metrics dataframe
2024-11-26 02:18:07,208:INFO:Uploading results into container
2024-11-26 02:18:07,209:INFO:Uploading model into container now
2024-11-26 02:18:07,209:INFO:_master_model_container: 9
2024-11-26 02:18:07,209:INFO:_display_container: 2
2024-11-26 02:18:07,210:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-26 02:18:07,210:INFO:create_model() successfully completed......................................
2024-11-26 02:18:07,339:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:07,339:INFO:Creating metrics dataframe
2024-11-26 02:18:07,345:INFO:Initializing Gradient Boosting Classifier
2024-11-26 02:18:07,345:INFO:Total runtime is 0.12023876905441283 minutes
2024-11-26 02:18:07,347:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:07,347:INFO:Initializing create_model()
2024-11-26 02:18:07,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:07,347:INFO:Checking exceptions
2024-11-26 02:18:07,347:INFO:Importing libraries
2024-11-26 02:18:07,347:INFO:Copying training dataset
2024-11-26 02:18:07,351:INFO:Defining folds
2024-11-26 02:18:07,351:INFO:Declaring metric variables
2024-11-26 02:18:07,353:INFO:Importing untrained model
2024-11-26 02:18:07,356:INFO:Gradient Boosting Classifier Imported successfully
2024-11-26 02:18:07,360:INFO:Starting cross validation
2024-11-26 02:18:07,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:07,898:INFO:Calculating mean and std
2024-11-26 02:18:07,898:INFO:Creating metrics dataframe
2024-11-26 02:18:07,900:INFO:Uploading results into container
2024-11-26 02:18:07,900:INFO:Uploading model into container now
2024-11-26 02:18:07,900:INFO:_master_model_container: 10
2024-11-26 02:18:07,900:INFO:_display_container: 2
2024-11-26 02:18:07,901:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-26 02:18:07,901:INFO:create_model() successfully completed......................................
2024-11-26 02:18:08,019:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:08,019:INFO:Creating metrics dataframe
2024-11-26 02:18:08,024:INFO:Initializing Linear Discriminant Analysis
2024-11-26 02:18:08,024:INFO:Total runtime is 0.1315636078516642 minutes
2024-11-26 02:18:08,027:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:08,027:INFO:Initializing create_model()
2024-11-26 02:18:08,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:08,027:INFO:Checking exceptions
2024-11-26 02:18:08,027:INFO:Importing libraries
2024-11-26 02:18:08,027:INFO:Copying training dataset
2024-11-26 02:18:08,031:INFO:Defining folds
2024-11-26 02:18:08,031:INFO:Declaring metric variables
2024-11-26 02:18:08,033:INFO:Importing untrained model
2024-11-26 02:18:08,036:INFO:Linear Discriminant Analysis Imported successfully
2024-11-26 02:18:08,041:INFO:Starting cross validation
2024-11-26 02:18:08,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:08,074:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:08,077:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:08,077:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:08,077:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:08,089:INFO:Calculating mean and std
2024-11-26 02:18:08,089:INFO:Creating metrics dataframe
2024-11-26 02:18:08,090:INFO:Uploading results into container
2024-11-26 02:18:08,091:INFO:Uploading model into container now
2024-11-26 02:18:08,091:INFO:_master_model_container: 11
2024-11-26 02:18:08,091:INFO:_display_container: 2
2024-11-26 02:18:08,091:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-26 02:18:08,091:INFO:create_model() successfully completed......................................
2024-11-26 02:18:08,215:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:08,215:INFO:Creating metrics dataframe
2024-11-26 02:18:08,221:INFO:Initializing Extra Trees Classifier
2024-11-26 02:18:08,221:INFO:Total runtime is 0.13484787543614704 minutes
2024-11-26 02:18:08,223:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:08,223:INFO:Initializing create_model()
2024-11-26 02:18:08,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:08,224:INFO:Checking exceptions
2024-11-26 02:18:08,224:INFO:Importing libraries
2024-11-26 02:18:08,224:INFO:Copying training dataset
2024-11-26 02:18:08,227:INFO:Defining folds
2024-11-26 02:18:08,227:INFO:Declaring metric variables
2024-11-26 02:18:08,230:INFO:Importing untrained model
2024-11-26 02:18:08,233:INFO:Extra Trees Classifier Imported successfully
2024-11-26 02:18:08,237:INFO:Starting cross validation
2024-11-26 02:18:08,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:08,463:INFO:Calculating mean and std
2024-11-26 02:18:08,464:INFO:Creating metrics dataframe
2024-11-26 02:18:08,465:INFO:Uploading results into container
2024-11-26 02:18:08,465:INFO:Uploading model into container now
2024-11-26 02:18:08,465:INFO:_master_model_container: 12
2024-11-26 02:18:08,465:INFO:_display_container: 2
2024-11-26 02:18:08,466:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-26 02:18:08,466:INFO:create_model() successfully completed......................................
2024-11-26 02:18:08,583:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:08,583:INFO:Creating metrics dataframe
2024-11-26 02:18:08,588:INFO:Initializing Extreme Gradient Boosting
2024-11-26 02:18:08,588:INFO:Total runtime is 0.14095919926961262 minutes
2024-11-26 02:18:08,590:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:08,590:INFO:Initializing create_model()
2024-11-26 02:18:08,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:08,590:INFO:Checking exceptions
2024-11-26 02:18:08,590:INFO:Importing libraries
2024-11-26 02:18:08,590:INFO:Copying training dataset
2024-11-26 02:18:08,593:INFO:Defining folds
2024-11-26 02:18:08,593:INFO:Declaring metric variables
2024-11-26 02:18:08,596:INFO:Importing untrained model
2024-11-26 02:18:08,600:INFO:Extreme Gradient Boosting Imported successfully
2024-11-26 02:18:08,604:INFO:Starting cross validation
2024-11-26 02:18:08,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:08,720:INFO:Calculating mean and std
2024-11-26 02:18:08,720:INFO:Creating metrics dataframe
2024-11-26 02:18:08,721:INFO:Uploading results into container
2024-11-26 02:18:08,721:INFO:Uploading model into container now
2024-11-26 02:18:08,722:INFO:_master_model_container: 13
2024-11-26 02:18:08,722:INFO:_display_container: 2
2024-11-26 02:18:08,722:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-26 02:18:08,722:INFO:create_model() successfully completed......................................
2024-11-26 02:18:08,841:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:08,841:INFO:Creating metrics dataframe
2024-11-26 02:18:08,847:INFO:Initializing Light Gradient Boosting Machine
2024-11-26 02:18:08,847:INFO:Total runtime is 0.14527471860249835 minutes
2024-11-26 02:18:08,849:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:08,849:INFO:Initializing create_model()
2024-11-26 02:18:08,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:08,849:INFO:Checking exceptions
2024-11-26 02:18:08,849:INFO:Importing libraries
2024-11-26 02:18:08,849:INFO:Copying training dataset
2024-11-26 02:18:08,852:INFO:Defining folds
2024-11-26 02:18:08,852:INFO:Declaring metric variables
2024-11-26 02:18:08,854:INFO:Importing untrained model
2024-11-26 02:18:08,856:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-26 02:18:08,860:INFO:Starting cross validation
2024-11-26 02:18:08,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:09,761:INFO:Calculating mean and std
2024-11-26 02:18:09,761:INFO:Creating metrics dataframe
2024-11-26 02:18:09,763:INFO:Uploading results into container
2024-11-26 02:18:09,763:INFO:Uploading model into container now
2024-11-26 02:18:09,763:INFO:_master_model_container: 14
2024-11-26 02:18:09,763:INFO:_display_container: 2
2024-11-26 02:18:09,765:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-26 02:18:09,765:INFO:create_model() successfully completed......................................
2024-11-26 02:18:09,904:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:09,904:INFO:Creating metrics dataframe
2024-11-26 02:18:09,911:INFO:Initializing Dummy Classifier
2024-11-26 02:18:09,911:INFO:Total runtime is 0.16301111380259195 minutes
2024-11-26 02:18:09,913:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:09,913:INFO:Initializing create_model()
2024-11-26 02:18:09,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678A2EBDD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:09,913:INFO:Checking exceptions
2024-11-26 02:18:09,914:INFO:Importing libraries
2024-11-26 02:18:09,914:INFO:Copying training dataset
2024-11-26 02:18:09,916:INFO:Defining folds
2024-11-26 02:18:09,917:INFO:Declaring metric variables
2024-11-26 02:18:09,919:INFO:Importing untrained model
2024-11-26 02:18:09,922:INFO:Dummy Classifier Imported successfully
2024-11-26 02:18:09,926:INFO:Starting cross validation
2024-11-26 02:18:09,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:09,947:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,949:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,949:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,951:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,952:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,953:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,954:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,955:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,957:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,957:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-26 02:18:09,963:INFO:Calculating mean and std
2024-11-26 02:18:09,963:INFO:Creating metrics dataframe
2024-11-26 02:18:09,964:INFO:Uploading results into container
2024-11-26 02:18:09,965:INFO:Uploading model into container now
2024-11-26 02:18:09,965:INFO:_master_model_container: 15
2024-11-26 02:18:09,965:INFO:_display_container: 2
2024-11-26 02:18:09,965:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-26 02:18:09,965:INFO:create_model() successfully completed......................................
2024-11-26 02:18:10,090:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:10,090:INFO:Creating metrics dataframe
2024-11-26 02:18:10,099:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-11-26 02:18:10,104:INFO:Initializing create_model()
2024-11-26 02:18:10,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:10,105:INFO:Checking exceptions
2024-11-26 02:18:10,106:INFO:Importing libraries
2024-11-26 02:18:10,106:INFO:Copying training dataset
2024-11-26 02:18:10,108:INFO:Defining folds
2024-11-26 02:18:10,108:INFO:Declaring metric variables
2024-11-26 02:18:10,108:INFO:Importing untrained model
2024-11-26 02:18:10,108:INFO:Declaring custom model
2024-11-26 02:18:10,109:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-26 02:18:10,109:INFO:Cross validation set to False
2024-11-26 02:18:10,109:INFO:Fitting Model
2024-11-26 02:18:10,120:INFO:[LightGBM] [Info] Number of positive: 46, number of negative: 3011
2024-11-26 02:18:10,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-11-26 02:18:10,121:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-26 02:18:10,121:INFO:[LightGBM] [Info] Total Bins 1268
2024-11-26 02:18:10,122:INFO:[LightGBM] [Info] Number of data points in the train set: 3057, number of used features: 6
2024-11-26 02:18:10,122:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015047 -> initscore=-4.181386
2024-11-26 02:18:10,122:INFO:[LightGBM] [Info] Start training from score -4.181386
2024-11-26 02:18:10,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,216:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-26 02:18:10,217:INFO:create_model() successfully completed......................................
2024-11-26 02:18:10,371:INFO:_master_model_container: 15
2024-11-26 02:18:10,372:INFO:_display_container: 2
2024-11-26 02:18:10,372:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-26 02:18:10,372:INFO:compare_models() successfully completed......................................
2024-11-26 02:18:10,372:INFO:Initializing finalize_model()
2024-11-26 02:18:10,372:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-11-26 02:18:10,373:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-26 02:18:10,375:INFO:Initializing create_model()
2024-11-26 02:18:10,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016787726310>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:10,375:INFO:Checking exceptions
2024-11-26 02:18:10,376:INFO:Importing libraries
2024-11-26 02:18:10,376:INFO:Copying training dataset
2024-11-26 02:18:10,376:INFO:Defining folds
2024-11-26 02:18:10,376:INFO:Declaring metric variables
2024-11-26 02:18:10,376:INFO:Importing untrained model
2024-11-26 02:18:10,376:INFO:Declaring custom model
2024-11-26 02:18:10,377:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-26 02:18:10,377:INFO:Cross validation set to False
2024-11-26 02:18:10,377:INFO:Fitting Model
2024-11-26 02:18:10,382:INFO:[LightGBM] [Info] Number of positive: 66, number of negative: 4302
2024-11-26 02:18:10,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-11-26 02:18:10,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-26 02:18:10,383:INFO:[LightGBM] [Info] Total Bins 1278
2024-11-26 02:18:10,383:INFO:[LightGBM] [Info] Number of data points in the train set: 4368, number of used features: 6
2024-11-26 02:18:10,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015110 -> initscore=-4.177181
2024-11-26 02:18:10,383:INFO:[LightGBM] [Info] Start training from score -4.177181
2024-11-26 02:18:10,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-26 02:18:10,506:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['UserId', 'recency', 'frequency',
                                             'sales_value_sum',
                                             'sales_value_mean',
                                             'transactions_last_month',
                                             'transactions_last_2weeks',
                                             'sales_value_last_2weeks',
                                             'sales_90_value'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-11-26 02:18:10,506:INFO:create_model() successfully completed......................................
2024-11-26 02:18:10,644:INFO:_master_model_container: 15
2024-11-26 02:18:10,644:INFO:_display_container: 2
2024-11-26 02:18:10,647:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['UserId', 'recency', 'frequency',
                                             'sales_value_sum',
                                             'sales_value_mean',
                                             'transactions_last_month',
                                             'transactions_last_2weeks',
                                             'sales_value_last_2weeks',
                                             'sales_90_value'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-11-26 02:18:10,647:INFO:finalize_model() successfully completed......................................
2024-11-26 02:18:32,142:INFO:PyCaret RegressionExperiment
2024-11-26 02:18:32,142:INFO:Logging name: reg-default-name
2024-11-26 02:18:32,143:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-26 02:18:32,143:INFO:version 3.3.2
2024-11-26 02:18:32,143:INFO:Initializing setup()
2024-11-26 02:18:32,143:INFO:self.USI: 8eb8
2024-11-26 02:18:32,143:INFO:self._variable_keys: {'gpu_param', 'X', 'fold_generator', 'X_test', 'fold_groups_param', 'exp_name_log', 'y', '_available_plots', 'idx', 'y_test', 'memory', 'exp_id', 'log_plots_param', 'X_train', 'target_param', '_ml_usecase', 'gpu_n_jobs_param', 'transform_target_param', 'logging_param', 'seed', 'y_train', 'USI', 'html_param', 'fold_shuffle_param', 'pipeline', 'data', 'n_jobs_param'}
2024-11-26 02:18:32,143:INFO:Checking environment
2024-11-26 02:18:32,143:INFO:python_version: 3.11.10
2024-11-26 02:18:32,143:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-11-26 02:18:32,143:INFO:machine: AMD64
2024-11-26 02:18:32,143:INFO:platform: Windows-10-10.0.22631-SP0
2024-11-26 02:18:32,144:INFO:Memory: svmem(total=16849256448, available=542068736, percent=96.8, used=16307187712, free=542068736)
2024-11-26 02:18:32,144:INFO:Physical Core: 10
2024-11-26 02:18:32,144:INFO:Logical Core: 16
2024-11-26 02:18:32,144:INFO:Checking libraries
2024-11-26 02:18:32,144:INFO:System:
2024-11-26 02:18:32,144:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-11-26 02:18:32,144:INFO:executable: c:\Users\vsneh\anaconda3\envs\ml_environment\python.exe
2024-11-26 02:18:32,145:INFO:   machine: Windows-10-10.0.22631-SP0
2024-11-26 02:18:32,145:INFO:PyCaret required dependencies:
2024-11-26 02:18:32,145:INFO:                 pip: 24.2
2024-11-26 02:18:32,145:INFO:          setuptools: 75.1.0
2024-11-26 02:18:32,145:INFO:             pycaret: 3.3.2
2024-11-26 02:18:32,145:INFO:             IPython: 8.27.0
2024-11-26 02:18:32,145:INFO:          ipywidgets: 8.1.5
2024-11-26 02:18:32,145:INFO:                tqdm: 4.66.5
2024-11-26 02:18:32,145:INFO:               numpy: 1.26.4
2024-11-26 02:18:32,145:INFO:              pandas: 2.1.4
2024-11-26 02:18:32,145:INFO:              jinja2: 3.1.4
2024-11-26 02:18:32,146:INFO:               scipy: 1.11.4
2024-11-26 02:18:32,146:INFO:              joblib: 1.3.2
2024-11-26 02:18:32,146:INFO:             sklearn: 1.4.2
2024-11-26 02:18:32,146:INFO:                pyod: 2.0.2
2024-11-26 02:18:32,146:INFO:            imblearn: 0.12.4
2024-11-26 02:18:32,146:INFO:   category_encoders: 2.6.4
2024-11-26 02:18:32,146:INFO:            lightgbm: 4.5.0
2024-11-26 02:18:32,146:INFO:               numba: 0.60.0
2024-11-26 02:18:32,146:INFO:            requests: 2.32.3
2024-11-26 02:18:32,146:INFO:          matplotlib: 3.7.5
2024-11-26 02:18:32,146:INFO:          scikitplot: 0.3.7
2024-11-26 02:18:32,146:INFO:         yellowbrick: 1.5
2024-11-26 02:18:32,146:INFO:              plotly: 5.24.1
2024-11-26 02:18:32,146:INFO:    plotly-resampler: Not installed
2024-11-26 02:18:32,147:INFO:             kaleido: 0.2.1
2024-11-26 02:18:32,147:INFO:           schemdraw: 0.15
2024-11-26 02:18:32,147:INFO:         statsmodels: 0.14.4
2024-11-26 02:18:32,147:INFO:              sktime: 0.26.0
2024-11-26 02:18:32,147:INFO:               tbats: 1.1.3
2024-11-26 02:18:32,147:INFO:            pmdarima: 2.0.4
2024-11-26 02:18:32,147:INFO:              psutil: 5.9.0
2024-11-26 02:18:32,147:INFO:          markupsafe: 2.1.3
2024-11-26 02:18:32,147:INFO:             pickle5: Not installed
2024-11-26 02:18:32,147:INFO:         cloudpickle: 3.0.0
2024-11-26 02:18:32,147:INFO:         deprecation: 2.1.0
2024-11-26 02:18:32,147:INFO:              xxhash: 3.5.0
2024-11-26 02:18:32,147:INFO:           wurlitzer: Not installed
2024-11-26 02:18:32,147:INFO:PyCaret optional dependencies:
2024-11-26 02:18:32,147:INFO:                shap: 0.46.0
2024-11-26 02:18:32,149:INFO:           interpret: Not installed
2024-11-26 02:18:32,149:INFO:                umap: Not installed
2024-11-26 02:18:32,149:INFO:     ydata_profiling: Not installed
2024-11-26 02:18:32,149:INFO:  explainerdashboard: Not installed
2024-11-26 02:18:32,149:INFO:             autoviz: Not installed
2024-11-26 02:18:32,149:INFO:           fairlearn: Not installed
2024-11-26 02:18:32,149:INFO:          deepchecks: Not installed
2024-11-26 02:18:32,149:INFO:             xgboost: 2.1.1
2024-11-26 02:18:32,149:INFO:            catboost: Not installed
2024-11-26 02:18:32,149:INFO:              kmodes: Not installed
2024-11-26 02:18:32,149:INFO:             mlxtend: Not installed
2024-11-26 02:18:32,149:INFO:       statsforecast: Not installed
2024-11-26 02:18:32,149:INFO:        tune_sklearn: Not installed
2024-11-26 02:18:32,149:INFO:                 ray: Not installed
2024-11-26 02:18:32,149:INFO:            hyperopt: Not installed
2024-11-26 02:18:32,149:INFO:              optuna: 4.1.0
2024-11-26 02:18:32,149:INFO:               skopt: Not installed
2024-11-26 02:18:32,149:INFO:              mlflow: 2.17.2
2024-11-26 02:18:32,149:INFO:              gradio: Not installed
2024-11-26 02:18:32,149:INFO:             fastapi: Not installed
2024-11-26 02:18:32,149:INFO:             uvicorn: Not installed
2024-11-26 02:18:32,149:INFO:              m2cgen: Not installed
2024-11-26 02:18:32,149:INFO:           evidently: Not installed
2024-11-26 02:18:32,149:INFO:               fugue: Not installed
2024-11-26 02:18:32,149:INFO:           streamlit: Not installed
2024-11-26 02:18:32,149:INFO:             prophet: Not installed
2024-11-26 02:18:32,149:INFO:None
2024-11-26 02:18:32,149:INFO:Set up data.
2024-11-26 02:18:32,155:INFO:Set up folding strategy.
2024-11-26 02:18:32,155:INFO:Set up train/test split.
2024-11-26 02:18:32,157:INFO:Set up index.
2024-11-26 02:18:32,157:INFO:Assigning column types.
2024-11-26 02:18:32,160:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-26 02:18:32,160:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,163:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,166:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,200:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,228:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,230:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,233:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,287:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,290:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-26 02:18:32,293:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,295:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,348:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,348:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,352:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,354:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,407:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,409:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-26 02:18:32,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,444:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,467:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,473:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,527:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,527:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,528:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-26 02:18:32,562:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,586:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,622:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,646:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,647:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-26 02:18:32,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,707:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-26 02:18:32,767:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,769:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-26 02:18:32,828:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,887:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:32,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:32,890:INFO:Preparing preprocessing pipeline...
2024-11-26 02:18:32,890:INFO:Set up simple imputation.
2024-11-26 02:18:32,903:INFO:Finished creating preprocessing pipeline.
2024-11-26 02:18:32,906:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vsneh\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['UserId', 'recency', 'frequency',
                                             'sales_value_sum',
                                             'sales_value_mean',
                                             'transactions_last_month',
                                             'transactions_last_2weeks',
                                             'sales_value_last_2weeks',
                                             'sales_90_flag'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-11-26 02:18:32,906:INFO:Creating final display dataframe.
2024-11-26 02:18:32,945:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    sales_90_value
2                   Target type        Regression
3           Original data shape        (4368, 10)
4        Transformed data shape        (4368, 10)
5   Transformed train set shape        (3057, 10)
6    Transformed test set shape        (1311, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8eb8
2024-11-26 02:18:33,006:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:33,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:33,086:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-26 02:18:33,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-26 02:18:33,089:INFO:setup() successfully completed in 0.95s...............
2024-11-26 02:18:43,776:INFO:Initializing compare_models()
2024-11-26 02:18:43,776:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-11-26 02:18:43,776:INFO:Checking exceptions
2024-11-26 02:18:43,777:INFO:Preparing display monitor
2024-11-26 02:18:43,793:INFO:Initializing Linear Regression
2024-11-26 02:18:43,794:INFO:Total runtime is 1.663366953531901e-05 minutes
2024-11-26 02:18:43,796:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:43,796:INFO:Initializing create_model()
2024-11-26 02:18:43,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:43,796:INFO:Checking exceptions
2024-11-26 02:18:43,797:INFO:Importing libraries
2024-11-26 02:18:43,797:INFO:Copying training dataset
2024-11-26 02:18:43,799:INFO:Defining folds
2024-11-26 02:18:43,799:INFO:Declaring metric variables
2024-11-26 02:18:43,801:INFO:Importing untrained model
2024-11-26 02:18:43,803:INFO:Linear Regression Imported successfully
2024-11-26 02:18:43,807:INFO:Starting cross validation
2024-11-26 02:18:43,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:43,857:INFO:Calculating mean and std
2024-11-26 02:18:43,857:INFO:Creating metrics dataframe
2024-11-26 02:18:43,859:INFO:Uploading results into container
2024-11-26 02:18:43,859:INFO:Uploading model into container now
2024-11-26 02:18:43,859:INFO:_master_model_container: 1
2024-11-26 02:18:43,859:INFO:_display_container: 2
2024-11-26 02:18:43,859:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2024-11-26 02:18:43,859:INFO:create_model() successfully completed......................................
2024-11-26 02:18:43,980:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:43,980:INFO:Creating metrics dataframe
2024-11-26 02:18:43,984:INFO:Initializing Lasso Regression
2024-11-26 02:18:43,984:INFO:Total runtime is 0.0031887372334798176 minutes
2024-11-26 02:18:43,986:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:43,986:INFO:Initializing create_model()
2024-11-26 02:18:43,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:43,987:INFO:Checking exceptions
2024-11-26 02:18:43,987:INFO:Importing libraries
2024-11-26 02:18:43,987:INFO:Copying training dataset
2024-11-26 02:18:43,990:INFO:Defining folds
2024-11-26 02:18:43,990:INFO:Declaring metric variables
2024-11-26 02:18:43,991:INFO:Importing untrained model
2024-11-26 02:18:43,994:INFO:Lasso Regression Imported successfully
2024-11-26 02:18:43,997:INFO:Starting cross validation
2024-11-26 02:18:43,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:44,022:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+10, tolerance: 5.163e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,022:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+10, tolerance: 4.748e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,029:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e+08, tolerance: 5.836e+05
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,032:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+10, tolerance: 5.192e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,032:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+10, tolerance: 5.188e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,035:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+10, tolerance: 5.136e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,037:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.623e+10, tolerance: 5.191e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,038:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+10, tolerance: 5.177e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,039:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+10, tolerance: 5.188e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,048:INFO:Calculating mean and std
2024-11-26 02:18:44,049:INFO:Creating metrics dataframe
2024-11-26 02:18:44,050:INFO:Uploading results into container
2024-11-26 02:18:44,050:INFO:Uploading model into container now
2024-11-26 02:18:44,050:INFO:_master_model_container: 2
2024-11-26 02:18:44,050:INFO:_display_container: 2
2024-11-26 02:18:44,050:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2024-11-26 02:18:44,050:INFO:create_model() successfully completed......................................
2024-11-26 02:18:44,170:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:44,170:INFO:Creating metrics dataframe
2024-11-26 02:18:44,174:INFO:Initializing Ridge Regression
2024-11-26 02:18:44,174:INFO:Total runtime is 0.006350294748942057 minutes
2024-11-26 02:18:44,176:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:44,176:INFO:Initializing create_model()
2024-11-26 02:18:44,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:44,176:INFO:Checking exceptions
2024-11-26 02:18:44,176:INFO:Importing libraries
2024-11-26 02:18:44,176:INFO:Copying training dataset
2024-11-26 02:18:44,179:INFO:Defining folds
2024-11-26 02:18:44,179:INFO:Declaring metric variables
2024-11-26 02:18:44,180:INFO:Importing untrained model
2024-11-26 02:18:44,182:INFO:Ridge Regression Imported successfully
2024-11-26 02:18:44,186:INFO:Starting cross validation
2024-11-26 02:18:44,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:44,199:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89325e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,202:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.00437e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,204:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89564e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,206:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89777e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,211:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89228e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,212:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89228e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,215:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89461e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,218:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.8929e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,220:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.89234e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-11-26 02:18:44,226:INFO:Calculating mean and std
2024-11-26 02:18:44,226:INFO:Creating metrics dataframe
2024-11-26 02:18:44,226:INFO:Uploading results into container
2024-11-26 02:18:44,227:INFO:Uploading model into container now
2024-11-26 02:18:44,227:INFO:_master_model_container: 3
2024-11-26 02:18:44,227:INFO:_display_container: 2
2024-11-26 02:18:44,227:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2024-11-26 02:18:44,227:INFO:create_model() successfully completed......................................
2024-11-26 02:18:44,346:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:44,347:INFO:Creating metrics dataframe
2024-11-26 02:18:44,350:INFO:Initializing Elastic Net
2024-11-26 02:18:44,350:INFO:Total runtime is 0.00929043690363566 minutes
2024-11-26 02:18:44,353:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:44,354:INFO:Initializing create_model()
2024-11-26 02:18:44,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:44,354:INFO:Checking exceptions
2024-11-26 02:18:44,354:INFO:Importing libraries
2024-11-26 02:18:44,354:INFO:Copying training dataset
2024-11-26 02:18:44,356:INFO:Defining folds
2024-11-26 02:18:44,357:INFO:Declaring metric variables
2024-11-26 02:18:44,358:INFO:Importing untrained model
2024-11-26 02:18:44,360:INFO:Elastic Net Imported successfully
2024-11-26 02:18:44,363:INFO:Starting cross validation
2024-11-26 02:18:44,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:44,382:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+10, tolerance: 5.163e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,385:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+10, tolerance: 4.748e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,391:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+10, tolerance: 5.192e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,391:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.245e+08, tolerance: 5.836e+05
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,397:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+10, tolerance: 5.191e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,399:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e+10, tolerance: 5.136e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,399:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.693e+10, tolerance: 5.188e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,402:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e+10, tolerance: 5.177e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,404:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+10, tolerance: 5.188e+06
  model = cd_fast.enet_coordinate_descent(

2024-11-26 02:18:44,411:INFO:Calculating mean and std
2024-11-26 02:18:44,411:INFO:Creating metrics dataframe
2024-11-26 02:18:44,412:INFO:Uploading results into container
2024-11-26 02:18:44,412:INFO:Uploading model into container now
2024-11-26 02:18:44,413:INFO:_master_model_container: 4
2024-11-26 02:18:44,413:INFO:_display_container: 2
2024-11-26 02:18:44,413:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2024-11-26 02:18:44,413:INFO:create_model() successfully completed......................................
2024-11-26 02:18:44,531:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:44,532:INFO:Creating metrics dataframe
2024-11-26 02:18:44,537:INFO:Initializing Least Angle Regression
2024-11-26 02:18:44,537:INFO:Total runtime is 0.01239928404490153 minutes
2024-11-26 02:18:44,539:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:44,539:INFO:Initializing create_model()
2024-11-26 02:18:44,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:44,539:INFO:Checking exceptions
2024-11-26 02:18:44,539:INFO:Importing libraries
2024-11-26 02:18:44,539:INFO:Copying training dataset
2024-11-26 02:18:44,542:INFO:Defining folds
2024-11-26 02:18:44,542:INFO:Declaring metric variables
2024-11-26 02:18:44,543:INFO:Importing untrained model
2024-11-26 02:18:44,545:INFO:Least Angle Regression Imported successfully
2024-11-26 02:18:44,549:INFO:Starting cross validation
2024-11-26 02:18:44,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:44,596:INFO:Calculating mean and std
2024-11-26 02:18:44,596:INFO:Creating metrics dataframe
2024-11-26 02:18:44,597:INFO:Uploading results into container
2024-11-26 02:18:44,597:INFO:Uploading model into container now
2024-11-26 02:18:44,597:INFO:_master_model_container: 5
2024-11-26 02:18:44,597:INFO:_display_container: 2
2024-11-26 02:18:44,597:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2024-11-26 02:18:44,597:INFO:create_model() successfully completed......................................
2024-11-26 02:18:44,717:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:44,717:INFO:Creating metrics dataframe
2024-11-26 02:18:44,722:INFO:Initializing Lasso Least Angle Regression
2024-11-26 02:18:44,722:INFO:Total runtime is 0.01548295815785726 minutes
2024-11-26 02:18:44,724:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:44,724:INFO:Initializing create_model()
2024-11-26 02:18:44,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:44,724:INFO:Checking exceptions
2024-11-26 02:18:44,724:INFO:Importing libraries
2024-11-26 02:18:44,725:INFO:Copying training dataset
2024-11-26 02:18:44,727:INFO:Defining folds
2024-11-26 02:18:44,727:INFO:Declaring metric variables
2024-11-26 02:18:44,729:INFO:Importing untrained model
2024-11-26 02:18:44,731:INFO:Lasso Least Angle Regression Imported successfully
2024-11-26 02:18:44,734:INFO:Starting cross validation
2024-11-26 02:18:44,735:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:44,785:INFO:Calculating mean and std
2024-11-26 02:18:44,786:INFO:Creating metrics dataframe
2024-11-26 02:18:44,787:INFO:Uploading results into container
2024-11-26 02:18:44,787:INFO:Uploading model into container now
2024-11-26 02:18:44,787:INFO:_master_model_container: 6
2024-11-26 02:18:44,787:INFO:_display_container: 2
2024-11-26 02:18:44,787:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2024-11-26 02:18:44,787:INFO:create_model() successfully completed......................................
2024-11-26 02:18:44,908:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:44,908:INFO:Creating metrics dataframe
2024-11-26 02:18:44,913:INFO:Initializing Orthogonal Matching Pursuit
2024-11-26 02:18:44,913:INFO:Total runtime is 0.018668782711029053 minutes
2024-11-26 02:18:44,915:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:44,916:INFO:Initializing create_model()
2024-11-26 02:18:44,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:44,916:INFO:Checking exceptions
2024-11-26 02:18:44,916:INFO:Importing libraries
2024-11-26 02:18:44,916:INFO:Copying training dataset
2024-11-26 02:18:44,918:INFO:Defining folds
2024-11-26 02:18:44,919:INFO:Declaring metric variables
2024-11-26 02:18:44,920:INFO:Importing untrained model
2024-11-26 02:18:44,922:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-26 02:18:44,926:INFO:Starting cross validation
2024-11-26 02:18:44,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:44,975:INFO:Calculating mean and std
2024-11-26 02:18:44,975:INFO:Creating metrics dataframe
2024-11-26 02:18:44,976:INFO:Uploading results into container
2024-11-26 02:18:44,977:INFO:Uploading model into container now
2024-11-26 02:18:44,977:INFO:_master_model_container: 7
2024-11-26 02:18:44,977:INFO:_display_container: 2
2024-11-26 02:18:44,977:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2024-11-26 02:18:44,977:INFO:create_model() successfully completed......................................
2024-11-26 02:18:45,100:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:45,100:INFO:Creating metrics dataframe
2024-11-26 02:18:45,105:INFO:Initializing Bayesian Ridge
2024-11-26 02:18:45,105:INFO:Total runtime is 0.021865832805633544 minutes
2024-11-26 02:18:45,107:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:45,107:INFO:Initializing create_model()
2024-11-26 02:18:45,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:45,107:INFO:Checking exceptions
2024-11-26 02:18:45,107:INFO:Importing libraries
2024-11-26 02:18:45,107:INFO:Copying training dataset
2024-11-26 02:18:45,111:INFO:Defining folds
2024-11-26 02:18:45,111:INFO:Declaring metric variables
2024-11-26 02:18:45,113:INFO:Importing untrained model
2024-11-26 02:18:45,117:INFO:Bayesian Ridge Imported successfully
2024-11-26 02:18:45,122:INFO:Starting cross validation
2024-11-26 02:18:45,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:45,177:INFO:Calculating mean and std
2024-11-26 02:18:45,177:INFO:Creating metrics dataframe
2024-11-26 02:18:45,179:INFO:Uploading results into container
2024-11-26 02:18:45,180:INFO:Uploading model into container now
2024-11-26 02:18:45,180:INFO:_master_model_container: 8
2024-11-26 02:18:45,180:INFO:_display_container: 2
2024-11-26 02:18:45,181:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2024-11-26 02:18:45,181:INFO:create_model() successfully completed......................................
2024-11-26 02:18:45,312:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:45,312:INFO:Creating metrics dataframe
2024-11-26 02:18:45,317:INFO:Initializing Passive Aggressive Regressor
2024-11-26 02:18:45,317:INFO:Total runtime is 0.025400328636169433 minutes
2024-11-26 02:18:45,319:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:45,319:INFO:Initializing create_model()
2024-11-26 02:18:45,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:45,320:INFO:Checking exceptions
2024-11-26 02:18:45,320:INFO:Importing libraries
2024-11-26 02:18:45,320:INFO:Copying training dataset
2024-11-26 02:18:45,323:INFO:Defining folds
2024-11-26 02:18:45,323:INFO:Declaring metric variables
2024-11-26 02:18:45,325:INFO:Importing untrained model
2024-11-26 02:18:45,328:INFO:Passive Aggressive Regressor Imported successfully
2024-11-26 02:18:45,333:INFO:Starting cross validation
2024-11-26 02:18:45,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:45,383:INFO:Calculating mean and std
2024-11-26 02:18:45,383:INFO:Creating metrics dataframe
2024-11-26 02:18:45,384:INFO:Uploading results into container
2024-11-26 02:18:45,384:INFO:Uploading model into container now
2024-11-26 02:18:45,385:INFO:_master_model_container: 9
2024-11-26 02:18:45,385:INFO:_display_container: 2
2024-11-26 02:18:45,385:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-26 02:18:45,385:INFO:create_model() successfully completed......................................
2024-11-26 02:18:45,504:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:45,504:INFO:Creating metrics dataframe
2024-11-26 02:18:45,509:INFO:Initializing Huber Regressor
2024-11-26 02:18:45,509:INFO:Total runtime is 0.028604559103647866 minutes
2024-11-26 02:18:45,511:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:45,511:INFO:Initializing create_model()
2024-11-26 02:18:45,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:45,511:INFO:Checking exceptions
2024-11-26 02:18:45,511:INFO:Importing libraries
2024-11-26 02:18:45,511:INFO:Copying training dataset
2024-11-26 02:18:45,515:INFO:Defining folds
2024-11-26 02:18:45,515:INFO:Declaring metric variables
2024-11-26 02:18:45,518:INFO:Importing untrained model
2024-11-26 02:18:45,521:INFO:Huber Regressor Imported successfully
2024-11-26 02:18:45,525:INFO:Starting cross validation
2024-11-26 02:18:45,525:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:45,574:INFO:Calculating mean and std
2024-11-26 02:18:45,575:INFO:Creating metrics dataframe
2024-11-26 02:18:45,576:INFO:Uploading results into container
2024-11-26 02:18:45,576:INFO:Uploading model into container now
2024-11-26 02:18:45,576:INFO:_master_model_container: 10
2024-11-26 02:18:45,576:INFO:_display_container: 2
2024-11-26 02:18:45,576:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2024-11-26 02:18:45,576:INFO:create_model() successfully completed......................................
2024-11-26 02:18:45,696:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:45,696:INFO:Creating metrics dataframe
2024-11-26 02:18:45,701:INFO:Initializing K Neighbors Regressor
2024-11-26 02:18:45,701:INFO:Total runtime is 0.03180536429087321 minutes
2024-11-26 02:18:45,704:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:45,704:INFO:Initializing create_model()
2024-11-26 02:18:45,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:45,704:INFO:Checking exceptions
2024-11-26 02:18:45,704:INFO:Importing libraries
2024-11-26 02:18:45,704:INFO:Copying training dataset
2024-11-26 02:18:45,707:INFO:Defining folds
2024-11-26 02:18:45,707:INFO:Declaring metric variables
2024-11-26 02:18:45,709:INFO:Importing untrained model
2024-11-26 02:18:45,713:INFO:K Neighbors Regressor Imported successfully
2024-11-26 02:18:45,717:INFO:Starting cross validation
2024-11-26 02:18:45,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:45,775:INFO:Calculating mean and std
2024-11-26 02:18:45,775:INFO:Creating metrics dataframe
2024-11-26 02:18:45,776:INFO:Uploading results into container
2024-11-26 02:18:45,776:INFO:Uploading model into container now
2024-11-26 02:18:45,777:INFO:_master_model_container: 11
2024-11-26 02:18:45,777:INFO:_display_container: 2
2024-11-26 02:18:45,777:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2024-11-26 02:18:45,777:INFO:create_model() successfully completed......................................
2024-11-26 02:18:45,897:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:45,897:INFO:Creating metrics dataframe
2024-11-26 02:18:45,902:INFO:Initializing Decision Tree Regressor
2024-11-26 02:18:45,903:INFO:Total runtime is 0.03517304658889771 minutes
2024-11-26 02:18:45,905:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:45,905:INFO:Initializing create_model()
2024-11-26 02:18:45,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:45,905:INFO:Checking exceptions
2024-11-26 02:18:45,905:INFO:Importing libraries
2024-11-26 02:18:45,905:INFO:Copying training dataset
2024-11-26 02:18:45,908:INFO:Defining folds
2024-11-26 02:18:45,908:INFO:Declaring metric variables
2024-11-26 02:18:45,910:INFO:Importing untrained model
2024-11-26 02:18:45,913:INFO:Decision Tree Regressor Imported successfully
2024-11-26 02:18:45,917:INFO:Starting cross validation
2024-11-26 02:18:45,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:45,966:INFO:Calculating mean and std
2024-11-26 02:18:45,966:INFO:Creating metrics dataframe
2024-11-26 02:18:45,967:INFO:Uploading results into container
2024-11-26 02:18:45,967:INFO:Uploading model into container now
2024-11-26 02:18:45,967:INFO:_master_model_container: 12
2024-11-26 02:18:45,967:INFO:_display_container: 2
2024-11-26 02:18:45,967:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2024-11-26 02:18:45,967:INFO:create_model() successfully completed......................................
2024-11-26 02:18:46,092:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:46,092:INFO:Creating metrics dataframe
2024-11-26 02:18:46,097:INFO:Initializing Random Forest Regressor
2024-11-26 02:18:46,097:INFO:Total runtime is 0.03839521408081055 minutes
2024-11-26 02:18:46,099:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:46,100:INFO:Initializing create_model()
2024-11-26 02:18:46,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:46,100:INFO:Checking exceptions
2024-11-26 02:18:46,100:INFO:Importing libraries
2024-11-26 02:18:46,100:INFO:Copying training dataset
2024-11-26 02:18:46,103:INFO:Defining folds
2024-11-26 02:18:46,103:INFO:Declaring metric variables
2024-11-26 02:18:46,105:INFO:Importing untrained model
2024-11-26 02:18:46,107:INFO:Random Forest Regressor Imported successfully
2024-11-26 02:18:46,111:INFO:Starting cross validation
2024-11-26 02:18:46,112:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:46,415:INFO:Calculating mean and std
2024-11-26 02:18:46,415:INFO:Creating metrics dataframe
2024-11-26 02:18:46,416:INFO:Uploading results into container
2024-11-26 02:18:46,416:INFO:Uploading model into container now
2024-11-26 02:18:46,417:INFO:_master_model_container: 13
2024-11-26 02:18:46,417:INFO:_display_container: 2
2024-11-26 02:18:46,417:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2024-11-26 02:18:46,418:INFO:create_model() successfully completed......................................
2024-11-26 02:18:46,541:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:46,541:INFO:Creating metrics dataframe
2024-11-26 02:18:46,547:INFO:Initializing Extra Trees Regressor
2024-11-26 02:18:46,548:INFO:Total runtime is 0.045902824401855474 minutes
2024-11-26 02:18:46,550:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:46,550:INFO:Initializing create_model()
2024-11-26 02:18:46,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:46,550:INFO:Checking exceptions
2024-11-26 02:18:46,550:INFO:Importing libraries
2024-11-26 02:18:46,550:INFO:Copying training dataset
2024-11-26 02:18:46,554:INFO:Defining folds
2024-11-26 02:18:46,554:INFO:Declaring metric variables
2024-11-26 02:18:46,556:INFO:Importing untrained model
2024-11-26 02:18:46,560:INFO:Extra Trees Regressor Imported successfully
2024-11-26 02:18:46,566:INFO:Starting cross validation
2024-11-26 02:18:46,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:46,753:INFO:Calculating mean and std
2024-11-26 02:18:46,753:INFO:Creating metrics dataframe
2024-11-26 02:18:46,755:INFO:Uploading results into container
2024-11-26 02:18:46,755:INFO:Uploading model into container now
2024-11-26 02:18:46,755:INFO:_master_model_container: 14
2024-11-26 02:18:46,756:INFO:_display_container: 2
2024-11-26 02:18:46,756:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2024-11-26 02:18:46,756:INFO:create_model() successfully completed......................................
2024-11-26 02:18:46,884:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:46,884:INFO:Creating metrics dataframe
2024-11-26 02:18:46,889:INFO:Initializing AdaBoost Regressor
2024-11-26 02:18:46,889:INFO:Total runtime is 0.05160264174143474 minutes
2024-11-26 02:18:46,891:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:46,891:INFO:Initializing create_model()
2024-11-26 02:18:46,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:46,891:INFO:Checking exceptions
2024-11-26 02:18:46,891:INFO:Importing libraries
2024-11-26 02:18:46,892:INFO:Copying training dataset
2024-11-26 02:18:46,894:INFO:Defining folds
2024-11-26 02:18:46,894:INFO:Declaring metric variables
2024-11-26 02:18:46,896:INFO:Importing untrained model
2024-11-26 02:18:46,897:INFO:AdaBoost Regressor Imported successfully
2024-11-26 02:18:46,901:INFO:Starting cross validation
2024-11-26 02:18:46,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:47,044:INFO:Calculating mean and std
2024-11-26 02:18:47,044:INFO:Creating metrics dataframe
2024-11-26 02:18:47,046:INFO:Uploading results into container
2024-11-26 02:18:47,046:INFO:Uploading model into container now
2024-11-26 02:18:47,046:INFO:_master_model_container: 15
2024-11-26 02:18:47,046:INFO:_display_container: 2
2024-11-26 02:18:47,046:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-11-26 02:18:47,047:INFO:create_model() successfully completed......................................
2024-11-26 02:18:47,167:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:47,167:INFO:Creating metrics dataframe
2024-11-26 02:18:47,174:INFO:Initializing Gradient Boosting Regressor
2024-11-26 02:18:47,174:INFO:Total runtime is 0.05634402831395467 minutes
2024-11-26 02:18:47,176:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:47,176:INFO:Initializing create_model()
2024-11-26 02:18:47,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:47,177:INFO:Checking exceptions
2024-11-26 02:18:47,177:INFO:Importing libraries
2024-11-26 02:18:47,177:INFO:Copying training dataset
2024-11-26 02:18:47,178:INFO:Defining folds
2024-11-26 02:18:47,179:INFO:Declaring metric variables
2024-11-26 02:18:47,181:INFO:Importing untrained model
2024-11-26 02:18:47,183:INFO:Gradient Boosting Regressor Imported successfully
2024-11-26 02:18:47,187:INFO:Starting cross validation
2024-11-26 02:18:47,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:47,652:INFO:Calculating mean and std
2024-11-26 02:18:47,652:INFO:Creating metrics dataframe
2024-11-26 02:18:47,654:INFO:Uploading results into container
2024-11-26 02:18:47,654:INFO:Uploading model into container now
2024-11-26 02:18:47,655:INFO:_master_model_container: 16
2024-11-26 02:18:47,655:INFO:_display_container: 2
2024-11-26 02:18:47,655:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-26 02:18:47,655:INFO:create_model() successfully completed......................................
2024-11-26 02:18:47,776:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:47,776:INFO:Creating metrics dataframe
2024-11-26 02:18:47,783:INFO:Initializing Extreme Gradient Boosting
2024-11-26 02:18:47,783:INFO:Total runtime is 0.06649768352508545 minutes
2024-11-26 02:18:47,785:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:47,785:INFO:Initializing create_model()
2024-11-26 02:18:47,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:47,785:INFO:Checking exceptions
2024-11-26 02:18:47,785:INFO:Importing libraries
2024-11-26 02:18:47,785:INFO:Copying training dataset
2024-11-26 02:18:47,787:INFO:Defining folds
2024-11-26 02:18:47,787:INFO:Declaring metric variables
2024-11-26 02:18:47,789:INFO:Importing untrained model
2024-11-26 02:18:47,792:INFO:Extreme Gradient Boosting Imported successfully
2024-11-26 02:18:47,797:INFO:Starting cross validation
2024-11-26 02:18:47,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:47,929:INFO:Calculating mean and std
2024-11-26 02:18:47,929:INFO:Creating metrics dataframe
2024-11-26 02:18:47,931:INFO:Uploading results into container
2024-11-26 02:18:47,931:INFO:Uploading model into container now
2024-11-26 02:18:47,932:INFO:_master_model_container: 17
2024-11-26 02:18:47,932:INFO:_display_container: 2
2024-11-26 02:18:47,932:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-11-26 02:18:47,932:INFO:create_model() successfully completed......................................
2024-11-26 02:18:48,054:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:48,055:INFO:Creating metrics dataframe
2024-11-26 02:18:48,061:INFO:Initializing Light Gradient Boosting Machine
2024-11-26 02:18:48,061:INFO:Total runtime is 0.07113402684529622 minutes
2024-11-26 02:18:48,063:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:48,063:INFO:Initializing create_model()
2024-11-26 02:18:48,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:48,063:INFO:Checking exceptions
2024-11-26 02:18:48,063:INFO:Importing libraries
2024-11-26 02:18:48,064:INFO:Copying training dataset
2024-11-26 02:18:48,066:INFO:Defining folds
2024-11-26 02:18:48,066:INFO:Declaring metric variables
2024-11-26 02:18:48,067:INFO:Importing untrained model
2024-11-26 02:18:48,070:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-26 02:18:48,074:INFO:Starting cross validation
2024-11-26 02:18:48,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:49,088:INFO:Calculating mean and std
2024-11-26 02:18:49,088:INFO:Creating metrics dataframe
2024-11-26 02:18:49,090:INFO:Uploading results into container
2024-11-26 02:18:49,091:INFO:Uploading model into container now
2024-11-26 02:18:49,091:INFO:_master_model_container: 18
2024-11-26 02:18:49,091:INFO:_display_container: 2
2024-11-26 02:18:49,091:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-11-26 02:18:49,091:INFO:create_model() successfully completed......................................
2024-11-26 02:18:49,235:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:49,236:INFO:Creating metrics dataframe
2024-11-26 02:18:49,242:INFO:Initializing Dummy Regressor
2024-11-26 02:18:49,242:INFO:Total runtime is 0.09082298676172892 minutes
2024-11-26 02:18:49,245:INFO:SubProcess create_model() called ==================================
2024-11-26 02:18:49,245:INFO:Initializing create_model()
2024-11-26 02:18:49,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001678DABBE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:49,245:INFO:Checking exceptions
2024-11-26 02:18:49,245:INFO:Importing libraries
2024-11-26 02:18:49,245:INFO:Copying training dataset
2024-11-26 02:18:49,248:INFO:Defining folds
2024-11-26 02:18:49,248:INFO:Declaring metric variables
2024-11-26 02:18:49,250:INFO:Importing untrained model
2024-11-26 02:18:49,252:INFO:Dummy Regressor Imported successfully
2024-11-26 02:18:49,256:INFO:Starting cross validation
2024-11-26 02:18:49,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-26 02:18:49,303:INFO:Calculating mean and std
2024-11-26 02:18:49,303:INFO:Creating metrics dataframe
2024-11-26 02:18:49,304:INFO:Uploading results into container
2024-11-26 02:18:49,304:INFO:Uploading model into container now
2024-11-26 02:18:49,305:INFO:_master_model_container: 19
2024-11-26 02:18:49,305:INFO:_display_container: 2
2024-11-26 02:18:49,305:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2024-11-26 02:18:49,305:INFO:create_model() successfully completed......................................
2024-11-26 02:18:49,425:INFO:SubProcess create_model() end ==================================
2024-11-26 02:18:49,425:INFO:Creating metrics dataframe
2024-11-26 02:18:49,433:WARNING:c:\Users\vsneh\anaconda3\envs\ml_environment\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-11-26 02:18:49,438:INFO:Initializing create_model()
2024-11-26 02:18:49,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:49,438:INFO:Checking exceptions
2024-11-26 02:18:49,440:INFO:Importing libraries
2024-11-26 02:18:49,440:INFO:Copying training dataset
2024-11-26 02:18:49,442:INFO:Defining folds
2024-11-26 02:18:49,442:INFO:Declaring metric variables
2024-11-26 02:18:49,442:INFO:Importing untrained model
2024-11-26 02:18:49,442:INFO:Declaring custom model
2024-11-26 02:18:49,443:INFO:AdaBoost Regressor Imported successfully
2024-11-26 02:18:49,443:INFO:Cross validation set to False
2024-11-26 02:18:49,443:INFO:Fitting Model
2024-11-26 02:18:49,531:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-11-26 02:18:49,531:INFO:create_model() successfully completed......................................
2024-11-26 02:18:49,668:INFO:_master_model_container: 19
2024-11-26 02:18:49,669:INFO:_display_container: 2
2024-11-26 02:18:49,669:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-11-26 02:18:49,669:INFO:compare_models() successfully completed......................................
2024-11-26 02:18:49,669:INFO:Initializing finalize_model()
2024-11-26 02:18:49,669:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-11-26 02:18:49,670:INFO:Finalizing AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-11-26 02:18:49,672:INFO:Initializing create_model()
2024-11-26 02:18:49,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001678A5AA910>, estimator=AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-11-26 02:18:49,672:INFO:Checking exceptions
2024-11-26 02:18:49,673:INFO:Importing libraries
2024-11-26 02:18:49,673:INFO:Copying training dataset
2024-11-26 02:18:49,674:INFO:Defining folds
2024-11-26 02:18:49,674:INFO:Declaring metric variables
2024-11-26 02:18:49,674:INFO:Importing untrained model
2024-11-26 02:18:49,674:INFO:Declaring custom model
2024-11-26 02:18:49,675:INFO:AdaBoost Regressor Imported successfully
2024-11-26 02:18:49,676:INFO:Cross validation set to False
2024-11-26 02:18:49,676:INFO:Fitting Model
2024-11-26 02:18:49,740:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['UserId', 'recency', 'frequency',
                                             'sales_value_sum',
                                             'sales_value_mean',
                                             'transactions_last_month',
                                             'transactions_last_2weeks',
                                             'sales_value_last_2weeks',
                                             'sales_90_flag'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_em...
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 AdaBoostRegressor(estimator=None, learning_rate=1.0,
                                   loss='linear', n_estimators=50,
                                   random_state=123))],
         verbose=False)
2024-11-26 02:18:49,740:INFO:create_model() successfully completed......................................
2024-11-26 02:18:49,862:INFO:_master_model_container: 19
2024-11-26 02:18:49,862:INFO:_display_container: 2
2024-11-26 02:18:49,864:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['UserId', 'recency', 'frequency',
                                             'sales_value_sum',
                                             'sales_value_mean',
                                             'transactions_last_month',
                                             'transactions_last_2weeks',
                                             'sales_value_last_2weeks',
                                             'sales_90_flag'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_em...
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 AdaBoostRegressor(estimator=None, learning_rate=1.0,
                                   loss='linear', n_estimators=50,
                                   random_state=123))],
         verbose=False)
2024-11-26 02:18:49,864:INFO:finalize_model() successfully completed......................................
